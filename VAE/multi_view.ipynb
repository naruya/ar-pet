{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- init weights ----\n",
      "   <class 'model.AE'>\n",
      "   <class 'model.Encoder'>\n",
      "ok <class 'torch.nn.modules.conv.Conv2d'>\n",
      "ok <class 'torch.nn.modules.conv.Conv2d'>\n",
      "ok <class 'torch.nn.modules.conv.Conv2d'>\n",
      "ok <class 'torch.nn.modules.conv.Conv2d'>\n",
      "ok <class 'torch.nn.modules.linear.Linear'>\n",
      "ok <class 'torch.nn.modules.linear.Linear'>\n",
      "ok <class 'torch.nn.modules.linear.Linear'>\n",
      "   <class 'model.Decoder'>\n",
      "ok <class 'torch.nn.modules.linear.Linear'>\n",
      "ok <class 'torch.nn.modules.conv.ConvTranspose2d'>\n",
      "ok <class 'torch.nn.modules.conv.ConvTranspose2d'>\n",
      "ok <class 'torch.nn.modules.conv.ConvTranspose2d'>\n",
      "ok <class 'torch.nn.modules.conv.ConvTranspose2d'>\n",
      "   <class 'torch.nn.modules.container.ModuleList'>\n",
      "using partial dataset\n",
      "using partial dataset\n",
      "using partial dataset\n",
      "using partial dataset\n",
      "using partial dataset\n",
      "using partial dataset\n",
      "using partial dataset\n",
      "using partial dataset\n",
      "using partial dataset\n",
      "using partial dataset\n",
      "(2027, 3, 64, 64) (2027, 3, 64, 64) (2027, 5)\n"
     ]
    }
   ],
   "source": [
    "from model import AE\n",
    "from data_loader import PetDataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch\n",
    "import torchvision\n",
    "from tqdm import tqdm\n",
    "from utils import *\n",
    "import numpy as np\n",
    "\n",
    "device=0\n",
    "\n",
    "import os\n",
    "from datetime import datetime\n",
    "import subprocess\n",
    "\n",
    "\n",
    "model = AE(device)\n",
    "load_model(model, \"Mar24_06-21-38_78feb91\", \"Mar24_06-23-13\")\n",
    "dataloader = PetDataLoader(device, B=256, shuffle=False)\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for batch in tqdm(dataloader):\n",
    "#     loss = model.train_(batch)\n",
    "#     print(loss.item())\n",
    "#     writer.add_scalar(\"loss\", loss.item(), itr)\n",
    "#     itr += 1\n",
    "    break\n",
    "\n",
    "# recons = model.reconst(batch)\n",
    "# recons = torch.cat([batch[\"img\"][:32].to(device), recons[:32]])\n",
    "# recons = torchvision.utils.make_grid(recons)\n",
    "\n",
    "# recons_f = model.reconst_f(batch)\n",
    "# recons_f = torch.cat([batch[\"img\"][:32].to(device), recons_f[:32]])\n",
    "# recons_f = torchvision.utils.make_grid(recons_f)\n",
    "\n",
    "# sample = model.sample_img(batch)\n",
    "# sample = torchvision.utils.make_grid(sample)\n",
    "\n",
    "# video = model.sample_vid(batch)\n",
    "\n",
    "# itr = 0\n",
    "\n",
    "# writer.add_image('recons', recons, itr)\n",
    "# writer.add_image('recons_f', recons_f, itr)\n",
    "# writer.add_image('sample', sample, itr)\n",
    "# writer.add_video('video', video, itr)\n",
    "# # writer.add_scalar(\"loss\", loss.item(), itr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(13.4154, device='cuda:0', grad_fn=<NormBackward0>)\n",
      "(256, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "recons = model.reconst(batch).detach().cpu().numpy().transpose(0,2,3,1)\n",
    "# recons = model.reconst_phi(batch, -np.pi/6.0).detach().cpu().numpy().transpose(0,2,3,1)\n",
    "print(recons.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux = batch[\"aux\"]\n",
    "# L = []\n",
    "# for i in range(256):\n",
    "#     t, x, y, w, h = aux[i]\n",
    "#     l = w if w > h else h\n",
    "#     L.append(l/64.0)\n",
    "# min(L), max(L) # 1 ~ 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 720, 960, 3)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "vid = []\n",
    "\n",
    "for i in range(256): # 256\n",
    "    aux = batch[\"aux\"]\n",
    "    t, x, y, w, h = aux[i]\n",
    "    l = w if w > h else h\n",
    "#     x = 1920 - (x+l)\n",
    "\n",
    "    target = (recons[i] * 255).astype(np.uint8)\n",
    "    target = cv2.resize(target, (l, l))\n",
    "#     plt.imshow(target)\n",
    "#     plt.show()\n",
    "\n",
    "    target = cv2.resize(target, (l, l))\n",
    "    bak_orig = (np.zeros((1440, 1920, 3)) + 51).astype(np.uint8)\n",
    "\n",
    "    bak_orig[y:y+l, x:x+l] += target\n",
    "    bak_orig = cv2.resize(bak_orig, (960,720))\n",
    "#     plt.imshow(bak_orig)\n",
    "#     plt.show()\n",
    "    vid.append(bak_orig)\n",
    "#     vid.append(bak_orig.transpose(2,0,1))\n",
    "\n",
    "vid = np.array(vid)\n",
    "# vid = np.array([vid])\n",
    "vid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid = np.concatenate([vid, vid2], axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t:   1%|          | 2/257 [00:00<00:14, 17.38it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Building file fish_01.gif with imageio.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    }
   ],
   "source": [
    "import moviepy.editor as mpy\n",
    "def npy_to_gif(npy, filename):\n",
    "    clip = mpy.ImageSequenceClip(list(npy), fps=10)\n",
    "    clip.write_gif(filename)\n",
    "npy_to_gif(vid, \"fish_01.gif\")\n",
    "\n",
    "# writer.add_video('fish_0', vid, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(377), tensor(137), tensor(659), tensor(290), tensor(170))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "t, x, y, w, h = aux[0]\n",
    "\n",
    "t, x, y, w, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid = []\n",
    "for i in range(4):\n",
    "    _img = self.sample_img(feed_dict)\n",
    "    vid.append(_img)\n",
    "vid = torch.stack(vid)\n",
    "return vid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
